{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2b9bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "tf.Tensor(35, shape=(), dtype=int32)\n",
      "0 [-0.74691105] [0.00099999]\n",
      "500 [-0.3731104] [0.34804583]\n",
      "1000 [-0.21300863] [0.40408438]\n",
      "1500 [-0.1105561] [0.36122796]\n",
      "2000 [-0.01404603] [0.31117767]\n",
      "2500 [0.06945173] [0.2677748]\n",
      "3000 [0.13174799] [0.23542407]\n",
      "3500 [0.1706939] [0.21520887]\n",
      "4000 [0.19023393] [0.20506814]\n",
      "4500 [0.19765516] [0.20121685]\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "# import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "a = tf.constant(15)\n",
    "b = tf.constant(20)\n",
    "print(a+b)\n",
    "# input\n",
    "x = np.random.rand(100).astype(np.float32)\n",
    "#print(x)\n",
    "# output - observed\n",
    "y = x * 0.2 + 0.2\n",
    "# Weight\n",
    "W = tf.Variable(tf.random.normal([1]))\n",
    "# bias\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "# Create a function for MSE - mean squared error\n",
    "def mse_loss():\n",
    "    ypred = W * x + b\n",
    "    loss = tf.reduce_mean(tf.square(ypred-y))\n",
    "    return loss\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# Iterations\n",
    "for step in range(5000):\n",
    "    optimizer.minimize(mse_loss,var_list=[W,b])\n",
    "    if step % 500 == 0:\n",
    "        print(step, W.numpy(), b.numpy())\n",
    "#print(mse_loss)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5996960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(767, 8)\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "762    0\n",
      "763    0\n",
      "764    0\n",
      "765    1\n",
      "766    0\n",
      "Name: 1, Length: 767, dtype: int64\n",
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 623us/step - loss: 7.6742 - accuracy: 0.5476\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 1.7607 - accuracy: 0.5789\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 553us/step - loss: 1.3508 - accuracy: 0.6115\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 1.2160 - accuracy: 0.6323\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 1.1651 - accuracy: 0.6428\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 1.0464 - accuracy: 0.6519\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 1.0114 - accuracy: 0.6245\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 598us/step - loss: 0.9743 - accuracy: 0.6323\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 611us/step - loss: 0.9008 - accuracy: 0.6258\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 526us/step - loss: 0.9227 - accuracy: 0.6154\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.8485 - accuracy: 0.6714\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.8041 - accuracy: 0.6258\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.7504 - accuracy: 0.6493\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.7643 - accuracy: 0.6375\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.7753 - accuracy: 0.6545\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 553us/step - loss: 0.7089 - accuracy: 0.6662\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.7074 - accuracy: 0.6532\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.7118 - accuracy: 0.6545\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 553us/step - loss: 0.6930 - accuracy: 0.6623\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.8314 - accuracy: 0.6219\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.7063 - accuracy: 0.6806\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 590us/step - loss: 0.6927 - accuracy: 0.6819\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 539us/step - loss: 0.6714 - accuracy: 0.6936\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.6995 - accuracy: 0.6610\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 600us/step - loss: 0.6492 - accuracy: 0.6701\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 553us/step - loss: 0.6365 - accuracy: 0.6910\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.6372 - accuracy: 0.6949\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6895 - accuracy: 0.6806\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.6801 - accuracy: 0.6767\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.6822 - accuracy: 0.6793\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.6621 - accuracy: 0.6688\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.6811 - accuracy: 0.6793\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 553us/step - loss: 0.6190 - accuracy: 0.6975\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.7049 - accuracy: 0.6858\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6421 - accuracy: 0.6741\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6259 - accuracy: 0.7027\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.6070 - accuracy: 0.6832\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6214 - accuracy: 0.6910\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5908 - accuracy: 0.7145\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.6314 - accuracy: 0.6897\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5877 - accuracy: 0.7158\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6280 - accuracy: 0.6897\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.6324 - accuracy: 0.7210\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.6284 - accuracy: 0.7014\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 618us/step - loss: 0.6119 - accuracy: 0.6975\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 599us/step - loss: 0.6016 - accuracy: 0.7066\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 553us/step - loss: 0.5825 - accuracy: 0.7171\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 618us/step - loss: 0.6438 - accuracy: 0.6975\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6080 - accuracy: 0.7040\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5636 - accuracy: 0.7275\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5826 - accuracy: 0.7093\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5781 - accuracy: 0.7223\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5981 - accuracy: 0.7236\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 539us/step - loss: 0.5684 - accuracy: 0.7366\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5760 - accuracy: 0.7249\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5651 - accuracy: 0.7301\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6074 - accuracy: 0.7053\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5561 - accuracy: 0.7288\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.6185 - accuracy: 0.7053\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5867 - accuracy: 0.7171\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5904 - accuracy: 0.7236\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6001 - accuracy: 0.7262\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 553us/step - loss: 0.5488 - accuracy: 0.7340\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5746 - accuracy: 0.7262\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5725 - accuracy: 0.7340\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 618us/step - loss: 0.5678 - accuracy: 0.7093\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 617us/step - loss: 0.5714 - accuracy: 0.7353\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5731 - accuracy: 0.7158\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5564 - accuracy: 0.7275\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 618us/step - loss: 0.5686 - accuracy: 0.7223\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5767 - accuracy: 0.7223\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5506 - accuracy: 0.7288\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5649 - accuracy: 0.7288\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5547 - accuracy: 0.7353\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5540 - accuracy: 0.7432\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 553us/step - loss: 0.5902 - accuracy: 0.7223\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5646 - accuracy: 0.7392\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5862 - accuracy: 0.7249\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5570 - accuracy: 0.7145\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5551 - accuracy: 0.7432\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5670 - accuracy: 0.7262\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5435 - accuracy: 0.7301\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5670 - accuracy: 0.7379\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5622 - accuracy: 0.7236\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5814 - accuracy: 0.7288\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5561 - accuracy: 0.7353\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5355 - accuracy: 0.7432\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 618us/step - loss: 0.5232 - accuracy: 0.7497\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5232 - accuracy: 0.7497\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5555 - accuracy: 0.7458\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5331 - accuracy: 0.7445\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5559 - accuracy: 0.7432\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5232 - accuracy: 0.7536\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5469 - accuracy: 0.7340\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5222 - accuracy: 0.7445\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5384 - accuracy: 0.7510\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5277 - accuracy: 0.7562\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5041 - accuracy: 0.7601\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5178 - accuracy: 0.7653\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5453 - accuracy: 0.7432\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5419 - accuracy: 0.7392\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5626 - accuracy: 0.7132\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5210 - accuracy: 0.7523\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5500 - accuracy: 0.7497\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5208 - accuracy: 0.7523\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5081 - accuracy: 0.7471\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4988 - accuracy: 0.7614\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5716 - accuracy: 0.7366\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5089 - accuracy: 0.7510\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5280 - accuracy: 0.7445\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5161 - accuracy: 0.7497\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5274 - accuracy: 0.7497\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5383 - accuracy: 0.7366\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5102 - accuracy: 0.7458\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5236 - accuracy: 0.7392\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4948 - accuracy: 0.7627\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4887 - accuracy: 0.7562\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4984 - accuracy: 0.7705\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4937 - accuracy: 0.7771\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5661 - accuracy: 0.7471\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5242 - accuracy: 0.7562\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5035 - accuracy: 0.7757\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4973 - accuracy: 0.7601\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5155 - accuracy: 0.7419\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5647 - accuracy: 0.7223\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5077 - accuracy: 0.7614\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5497 - accuracy: 0.7340\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5107 - accuracy: 0.7549\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4892 - accuracy: 0.7536\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5109 - accuracy: 0.7575\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 618us/step - loss: 0.5243 - accuracy: 0.7523\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5038 - accuracy: 0.7614\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5116 - accuracy: 0.7523\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5680 - accuracy: 0.7432\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5036 - accuracy: 0.7562\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4954 - accuracy: 0.7575\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5307 - accuracy: 0.7340\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5423 - accuracy: 0.7471\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5416 - accuracy: 0.7523\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5376 - accuracy: 0.7484\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4877 - accuracy: 0.7692\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4888 - accuracy: 0.7627\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5226 - accuracy: 0.7445\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5363 - accuracy: 0.7379\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 618us/step - loss: 0.5168 - accuracy: 0.7536\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4971 - accuracy: 0.7614\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.4843 - accuracy: 0.7653\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4948 - accuracy: 0.7692\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5074 - accuracy: 0.7653\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5169 - accuracy: 0.7640\n",
      "24/24 [==============================] - 0s 609us/step - loss: 0.4708 - accuracy: 0.7888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4708038568496704, 0.7887874841690063]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 - Load the dataset\n",
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "## INPUT Variables ##\n",
    "# x1 - Number of times pregnant\n",
    "# x2 - plasma glucose\n",
    "# x3 - diastolic blood pressure\n",
    "# x4 - Triceps skin fold thickness\n",
    "# x5 - 2-hour serum insulin\n",
    "# x6 - bmi\n",
    "# x7 - diabetes pedigree function\n",
    "# x8 - age (yrs)\n",
    "## Output Variable ##\n",
    "# Class Variable - 0 or 1\n",
    "dataset = pd.read_csv(\"pima-indians-diabetes.csv\")\n",
    "dataset.head()\n",
    "# [:,:] - first : is range of rows and second : is columns\n",
    "# [start:end] - begins at start, ends at end-1\n",
    "x = dataset.iloc[:,0:8]\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "y = dataset.iloc[:,8]\n",
    "print(y)\n",
    "# Step 2 - Creating or define the Keras Model\n",
    "# Sequential Model\n",
    "# Layer1 -> Layer2 -> Layer3\n",
    "model = Sequential()\n",
    "# The model expects row of data with 8 variables\n",
    "# 12 = nodes\n",
    "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "# Hidden Layer\n",
    "# 8 = nodes\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# Output layer\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "# Step 3 - Compile the Keras model\n",
    "# loss (error)\n",
    "# optimizer (adam)\n",
    "# metrics = accuracy\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#Step 4 - Fit / Train the model\n",
    "#1 = Epochs - number of iterations / passes\n",
    "#2 - Batch - sample data\n",
    "model.fit(x,y, epochs=150, batch_size=10)\n",
    "# Step 5 - evaluate the model\n",
    "model.evaluate(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89afa4a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6  148  72  35    0  33.6  0.627  50  1\n",
       "0  1   85  66  29    0  26.6  0.351  31  0\n",
       "1  8  183  64   0    0  23.3  0.672  32  1\n",
       "2  1   89  66  23   94  28.1  0.167  21  0\n",
       "3  0  137  40  35  168  43.1  2.288  33  1\n",
       "4  5  116  74   0    0  25.6  0.201  30  0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce892a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/74/07/edce54779f5c3fe8ab8390eafad3d7c8190fce68f922a254ea77f4a94a99/torch-2.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torch-2.1.0-cp311-cp311-win_amd64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ananyapranav\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.1.0-cp311-cp311-win_amd64.whl (192.3 MB)\n",
      "   ---------------------------------------- 0.0/192.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/192.3 MB 2.8 MB/s eta 0:01:08\n",
      "   ---------------------------------------- 0.4/192.3 MB 4.6 MB/s eta 0:00:42\n",
      "   ---------------------------------------- 0.9/192.3 MB 6.6 MB/s eta 0:00:29\n",
      "   ---------------------------------------- 1.4/192.3 MB 7.6 MB/s eta 0:00:26\n",
      "   ---------------------------------------- 2.0/192.3 MB 8.7 MB/s eta 0:00:22\n",
      "    --------------------------------------- 2.8/192.3 MB 9.7 MB/s eta 0:00:20\n",
      "    --------------------------------------- 3.5/192.3 MB 10.5 MB/s eta 0:00:19\n",
      "    --------------------------------------- 4.2/192.3 MB 11.1 MB/s eta 0:00:18\n",
      "    --------------------------------------- 4.8/192.3 MB 11.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 5.4/192.3 MB 11.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 6.1/192.3 MB 11.9 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 7.0/192.3 MB 12.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 7.6/192.3 MB 12.5 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 8.4/192.3 MB 12.8 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 9.1/192.3 MB 13.2 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 10.0/192.3 MB 13.6 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 10.3/192.3 MB 13.6 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 11.3/192.3 MB 15.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 12.3/192.3 MB 16.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 13.2/192.3 MB 16.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 13.8/192.3 MB 15.6 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 14.9/192.3 MB 16.8 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 15.7/192.3 MB 16.8 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 16.6/192.3 MB 17.7 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 17.6/192.3 MB 17.7 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 18.6/192.3 MB 18.2 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 19.3/192.3 MB 17.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 20.3/192.3 MB 19.3 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 21.2/192.3 MB 18.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 21.9/192.3 MB 18.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 22.7/192.3 MB 18.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 23.6/192.3 MB 18.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 24.7/192.3 MB 18.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 25.3/192.3 MB 18.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 26.3/192.3 MB 17.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 27.2/192.3 MB 18.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 27.9/192.3 MB 17.7 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 28.9/192.3 MB 17.7 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 29.4/192.3 MB 17.7 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 30.4/192.3 MB 17.7 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 31.1/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 32.0/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 32.8/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 33.8/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 34.5/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 35.4/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 36.4/192.3 MB 17.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 37.3/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 38.2/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 39.1/192.3 MB 18.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 39.7/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 40.7/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 41.1/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 42.1/192.3 MB 18.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 42.8/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 43.7/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 44.5/192.3 MB 18.2 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 45.2/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 46.2/192.3 MB 17.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 47.0/192.3 MB 17.2 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 48.1/192.3 MB 17.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 48.9/192.3 MB 17.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 49.8/192.3 MB 17.7 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 50.8/192.3 MB 17.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 52.1/192.3 MB 18.7 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 53.1/192.3 MB 19.3 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 53.8/192.3 MB 18.7 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 54.7/192.3 MB 18.7 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 55.6/192.3 MB 19.2 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 56.6/192.3 MB 19.8 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 57.4/192.3 MB 19.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 58.4/192.3 MB 19.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 59.4/192.3 MB 19.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 60.5/192.3 MB 19.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 61.3/192.3 MB 20.5 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 62.2/192.3 MB 19.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 63.2/192.3 MB 19.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 64.1/192.3 MB 20.5 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 64.8/192.3 MB 19.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 65.7/192.3 MB 19.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 66.7/192.3 MB 19.9 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 67.3/192.3 MB 19.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 68.2/192.3 MB 19.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 69.0/192.3 MB 18.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 69.7/192.3 MB 18.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 70.6/192.3 MB 18.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 71.6/192.3 MB 18.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 72.0/192.3 MB 17.3 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 73.2/192.3 MB 17.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 73.9/192.3 MB 17.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 74.9/192.3 MB 17.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 75.4/192.3 MB 16.8 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 76.3/192.3 MB 17.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 77.2/192.3 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 77.9/192.3 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 78.8/192.3 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 79.7/192.3 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 80.6/192.3 MB 17.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 81.6/192.3 MB 17.7 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 82.4/192.3 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 83.4/192.3 MB 18.7 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 84.1/192.3 MB 18.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 84.9/192.3 MB 18.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 86.0/192.3 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 87.2/192.3 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 88.1/192.3 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 89.1/192.3 MB 19.9 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 89.9/192.3 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 90.8/192.3 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 91.7/192.3 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 92.6/192.3 MB 19.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 93.7/192.3 MB 19.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 94.6/192.3 MB 19.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 95.5/192.3 MB 19.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 96.5/192.3 MB 19.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 97.4/192.3 MB 19.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 98.2/192.3 MB 19.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 99.2/192.3 MB 19.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 100.2/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 101.1/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 102.0/192.3 MB 20.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 102.7/192.3 MB 19.3 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 103.8/192.3 MB 19.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 104.3/192.3 MB 18.7 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 105.4/192.3 MB 18.7 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 106.5/192.3 MB 18.7 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 107.1/192.3 MB 18.7 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 107.9/192.3 MB 17.7 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 108.9/192.3 MB 18.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 109.8/192.3 MB 18.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 110.6/192.3 MB 18.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 111.4/192.3 MB 18.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 112.2/192.3 MB 18.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 113.3/192.3 MB 18.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 114.2/192.3 MB 18.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 115.0/192.3 MB 18.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 115.9/192.3 MB 19.3 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 116.9/192.3 MB 18.7 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 117.8/192.3 MB 18.7 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 118.7/192.3 MB 19.2 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 119.6/192.3 MB 19.2 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 120.6/192.3 MB 19.3 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 121.7/192.3 MB 19.3 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 122.5/192.3 MB 19.8 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 123.5/192.3 MB 19.2 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 124.5/192.3 MB 19.8 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 125.3/192.3 MB 19.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 126.2/192.3 MB 19.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 127.2/192.3 MB 20.5 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 127.8/192.3 MB 18.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 128.8/192.3 MB 19.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 129.8/192.3 MB 18.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 130.5/192.3 MB 18.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 131.6/192.3 MB 19.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 132.7/192.3 MB 19.9 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 133.9/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 134.5/192.3 MB 19.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 135.4/192.3 MB 19.8 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 136.3/192.3 MB 19.8 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 137.3/192.3 MB 19.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 138.3/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 139.1/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 140.1/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 141.2/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 142.3/192.3 MB 20.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 143.4/192.3 MB 21.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 144.5/192.3 MB 21.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 145.3/192.3 MB 21.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 146.3/192.3 MB 21.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 147.4/192.3 MB 21.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 148.3/192.3 MB 21.1 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 149.2/192.3 MB 21.9 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 150.3/192.3 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 151.5/192.3 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 152.3/192.3 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 153.4/192.3 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 154.2/192.3 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 155.1/192.3 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 156.1/192.3 MB 20.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 157.1/192.3 MB 20.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 158.2/192.3 MB 21.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 159.0/192.3 MB 20.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 160.0/192.3 MB 20.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 161.2/192.3 MB 20.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 162.0/192.3 MB 20.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 163.1/192.3 MB 20.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 164.2/192.3 MB 21.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 165.5/192.3 MB 21.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 166.5/192.3 MB 22.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 167.5/192.3 MB 21.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 168.7/192.3 MB 22.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 169.7/192.3 MB 22.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 170.6/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 171.7/192.3 MB 22.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 173.0/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 173.8/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 175.0/192.3 MB 23.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 176.0/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 176.7/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 178.0/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 178.6/192.3 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 179.8/192.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 181.2/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 182.3/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 183.5/192.3 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 185.0/192.3 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 186.2/192.3 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  187.5/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  188.7/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  190.1/192.3 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  191.4/192.3 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  192.3/192.3 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 192.3/192.3 MB 5.5 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\ANANYAPRANAV\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f4bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "<class 'torch.Tensor'>\n",
      "One Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.5079, 0.2607],\n",
      "        [0.7267, 0.5785]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    " # Two major objectives of PyTorch\n",
    "#1. Replacement of Numpy to use the power of GPUs and other accelerators\n",
    "#2. Automatic Differentiation Library helps in implementation of Neural Networks\n",
    "\n",
    "# Feed Forward --> first stage\n",
    "# Back Propagation --> second stage (differentiation)\n",
    "# Tensors - Special Data Structures\n",
    "# similar to an array, matrices\n",
    "# similar to Numpy ndarrays\n",
    "import torch\n",
    "import numpy as np\n",
    "# Tensor Initialization\n",
    "### multiple ways\n",
    "### 1 - using data\n",
    "data = [\n",
    "[1,2],\n",
    "[3,4]\n",
    "]\n",
    "x_data = torch.tensor(data)\n",
    "print(type(x_data))\n",
    "\n",
    "### 2 - using numpy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)\n",
    "print(type(x_np))\n",
    "\n",
    "### 3 - using another tensor\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(\"One Tensor: \\n\",x_ones)\n",
    "\n",
    "x_rand = torch.rand_like(x_data,dtype=torch.float)\n",
    "print(x_rand)\n",
    "\n",
    "#### more ways to create tensors\n",
    "#shape = (2,3)\n",
    "#random_tensor = torch.rand(shape)\n",
    "#print(random_tensor)\n",
    "#print(type(random_tensor))\n",
    "#ones_tensor = torch.ones(shape)\n",
    "#print(ones_tensor)\n",
    "#print(type(ones_tensor))\n",
    "#zeros_tensor = torch.zeros(shape)\n",
    "#print(zeros_tensor)\n",
    "#print(type(zeros_tensor))\n",
    "#tensor = torch.rand(3,4)\n",
    "#print(tensor)\n",
    "#tensor.shape\n",
    "#tensor.dtype\n",
    "#tensor.device\n",
    "# Tensor Operations\n",
    "#if torch.cuda.is_available():\n",
    " #   tensor = tensor.to('cuda')\n",
    "  #  print(\"Device tensor is stored in \", tensor.device)\n",
    "\n",
    "\n",
    "# Indexing, Slicing\n",
    "tensor = torch.ones(4,4)\n",
    "print(tensor)\n",
    "print(tensor)\n",
    "\n",
    "tensor1 = torch.zeros(4,4)\n",
    "print(tensor1)\n",
    "\n",
    "tensor2 = torch.cat([tensor,tensor1])\n",
    "print(tensor2)\n",
    "\n",
    "\n",
    "# Multiply Operation\n",
    "tensor.mul(tensor1)\n",
    "tensor * tensor1\n",
    "tensor.T\n",
    "\n",
    "# inplace - change the original tensor\n",
    "tensor.add_(3)\n",
    "print(tensor)\n",
    "\n",
    "# from tensor to numpy\n",
    "t = torch.ones(5)\n",
    "print(t)\n",
    "\n",
    "n = t.numpy()\n",
    "print(n)\n",
    "print(type(n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
